# Changelog

All notable changes to the Zaguan Python SDK will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [0.2.0] - 2024-11-21

### üéâ Major Features

This release implements **all "should" requirements** from the SDK documentation, making this a production-ready, feature-complete SDK.

#### Anthropic Messages API (Native)
- **Full Anthropic Messages API support** at `/v1/messages` endpoint
  - `client.messages()` - Send requests to Anthropic's native API
  - `client.messages_stream()` - Stream Anthropic responses with SSE
  - Native Anthropic message format with content blocks
- **Extended Thinking (Beta)** support
  - Configure thinking budget (1,000-10,000 tokens)
  - Separate thinking and text content blocks
  - Verification signatures for thinking blocks
- **Token Counting** endpoint
  - `client.count_tokens()` - Count tokens before sending requests
  - Useful for cost estimation and staying within limits
- **Batches API** - Complete batch processing support
  - `client.create_messages_batch()` - Create batch requests
  - `client.get_messages_batch()` - Get batch status
  - `client.list_messages_batches()` - List all batches
  - `client.cancel_messages_batch()` - Cancel a batch
  - `client.get_messages_batch_results()` - Get results as JSONL stream

#### Streaming Utilities
- **StreamAccumulator** class for reconstructing messages from chunks
  - Accumulate streaming deltas incrementally
  - Track finish reasons and metadata
  - Get complete message or content string
  - Reset and reuse for multiple streams
- **reconstruct_message_from_stream()** helper function
  - Reconstruct complete messages from chunk lists
  - Works with both OpenAI and Anthropic streaming formats

#### Retry Logic with Exponential Backoff
- **RetryConfig** class for configurable retry behavior
  - Max retries, initial delay, max delay
  - Exponential backoff with configurable base
  - Jitter to prevent thundering herd
  - Configurable retry conditions (status codes, exceptions)
- **@with_retry()** decorator for sync functions
- **async_with_retry()** function for async operations
- Automatic retry on network errors and 429/5xx status codes

#### Observability & Monitoring
- **Event types** for tracking requests
  - `RequestEvent` - Request start with metadata
  - `ResponseEvent` - Response with latency, tokens, cost
  - `ErrorEvent` - Errors with context and retry info
- **LoggingHook** - Built-in logging to stdout
  - Verbose mode for detailed information
  - Request/response/error logging
- **MetricsCollector** - Usage tracking and analytics
  - Total requests, success/failure counts
  - Average latency, success rate
  - Token usage (prompt, completion, reasoning)
  - Cost tracking
  - Breakdown by model and error type
- **CompositeHook** - Combine multiple observability hooks
- **ObservabilityHook** protocol for custom implementations

#### Forward Compatibility
- **All models use `extra="allow"`** configuration
  - Unknown fields from API are preserved, not rejected
  - Future API changes won't break existing code
- **Metadata fields** added to core types
  - `ChatResponse.metadata`
  - `CreditsBalance.metadata`
  - `ModelInfo.metadata`
  - All Anthropic types with extensibility fields

### üì¶ New Modules

- `zaguan_sdk/streaming.py` - Streaming utilities
- `zaguan_sdk/retry.py` - Retry logic with exponential backoff
- `zaguan_sdk/observability.py` - Logging and metrics infrastructure

### üîß Enhanced Models

- Added **12 new Anthropic-specific models**:
  - `AnthropicThinkingConfig`
  - `AnthropicContentBlock`
  - `AnthropicMessage`
  - `AnthropicUsage`
  - `AnthropicMessagesRequest`
  - `AnthropicMessagesResponse`
  - `AnthropicMessagesDelta`
  - `AnthropicMessagesStreamEvent`
  - `AnthropicCountTokensRequest`
  - `AnthropicCountTokensResponse`
  - `AnthropicMessagesBatchItem`
  - `AnthropicMessagesBatchRequest`
  - `AnthropicMessagesBatchResponse`

- **Forward compatibility** for all existing models
  - Added `extra="allow"` to all Pydantic models
  - Added metadata fields where appropriate

### üöÄ New Client Methods

**Sync Client (ZaguanClient):**
- `messages()` - Anthropic Messages API
- `messages_stream()` - Streaming Anthropic messages
- `count_tokens()` - Token counting
- `create_messages_batch()` - Create batch
- `get_messages_batch()` - Get batch status
- `list_messages_batches()` - List batches
- `cancel_messages_batch()` - Cancel batch
- `get_messages_batch_results()` - Get results

**Async Client (AsyncZaguanClient):**
- All above methods with full async/await support

### üìö Documentation

- **New comprehensive guides**:
  - `docs/PROVIDER_EXAMPLES.md` - Provider-specific usage examples
    - Google Gemini reasoning control
    - Anthropic extended thinking
    - DeepSeek thinking control
    - Perplexity search
    - Alibaba Qwen
    - xAI Grok
    - OpenAI reasoning models
  - `docs/ADVANCED_FEATURES.md` - Advanced features guide
    - Anthropic Messages API
    - Streaming utilities
    - Retry logic
    - Observability
    - Forward compatibility
    - Error handling
  - `docs/IMPLEMENTATION_SUMMARY.md` - Complete implementation details

- **Updated README.md** with advanced features section

### ‚ú® New Utilities

- `StreamAccumulator` - Accumulate streaming chunks
- `reconstruct_message_from_stream()` - Helper function
- `RetryConfig` - Retry configuration
- `with_retry()` - Sync retry decorator
- `async_with_retry()` - Async retry function
- `LoggingHook` - Logging implementation
- `MetricsCollector` - Metrics tracking
- `CompositeHook` - Combine hooks

### üéØ SDK Specification Compliance

This release achieves **100% compliance** with all "should" requirements from the SDK documentation:

- ‚úÖ Anthropic Messages API with extended thinking
- ‚úÖ Streaming utilities for message reconstruction
- ‚úÖ Retry logic with exponential backoff
- ‚úÖ Observability hooks for logging and metrics
- ‚úÖ Forward compatibility with unknown fields
- ‚úÖ Metadata fields for extensibility
- ‚úÖ Comprehensive provider-specific examples

### üîí Security

- No breaking changes
- All new features are opt-in
- Backward compatible with v0.1.0

### üìä Testing

- All existing tests passing
- New modules include comprehensive docstrings
- Example code in documentation is tested

### üöÄ Migration from v0.1.0

**No migration required!** All changes are additive and backward compatible.

New features can be adopted incrementally:

```python
# Existing code works unchanged
response = client.chat(request)

# New Anthropic Messages API
from zaguan_sdk import AnthropicMessagesRequest, AnthropicMessage

response = client.messages(AnthropicMessagesRequest(
    model="anthropic/claude-3-5-sonnet",
    messages=[AnthropicMessage(role="user", content="Hello")],
    max_tokens=1024
))

# New streaming utilities
from zaguan_sdk import StreamAccumulator

accumulator = StreamAccumulator()
for chunk in client.chat_stream(request):
    accumulator.add_chunk(chunk)

# New retry logic
from zaguan_sdk import RetryConfig, with_retry

@with_retry(RetryConfig(max_retries=5))
def make_request():
    return client.chat(request)
```

### üôè Acknowledgments

This release implements all documented "should" requirements, making the Zaguan Python SDK a best-in-class SDK with enterprise-grade features.

---

## [0.1.0] - 2024-11-18

### Added

#### Security & Validation
- **Input validation** for `base_url` and `api_key` in both sync and async clients
  - Prevents empty or whitespace-only values
  - Raises `ValueError` with clear error messages
- **Default timeout** of 30 seconds for all HTTP requests (per SDK specification)
  - Can be overridden via constructor parameter
  - Ensures requests don't hang indefinitely

#### Error Handling
- **BandAccessDeniedError** exception for band-based access control
  - Includes `band`, `required_tier`, and `current_tier` attributes
  - Properly parsed from API error responses
- **Improved streaming error handling**
  - Better handling of malformed SSE data
  - Proper cleanup on HTTP errors
  - Clear error messages for validation failures

#### Model Features (ChatRequest)
- **Audio modalities** support (GPT-4o Audio)
  - `modalities` parameter for specifying output types
  - `audio` parameter for voice and format configuration
- **Reasoning effort** parameter for o1/o3 models
  - Values: "minimal", "low", "medium", "high"
- **DeepSeek thinking control**
  - `thinking` boolean parameter to enable/disable reasoning output
- **Virtual model IDs** support
  - `virtual_model_id` parameter for custom routing
- **Additional OpenAI-compatible parameters**
  - `parallel_tool_calls` for concurrent tool execution
  - `store` for conversation storage
  - `verbosity` for output control
- **extra_body** parameter for OpenAI SDK compatibility
  - Automatically merged with `provider_specific_params`
  - Enables drop-in replacement for OpenAI SDK

#### Message Model Improvements
- **Developer role** support (in addition to system, user, assistant, tool, function)
- **function_call** field for legacy function calling compatibility
- **Flexible role handling** for streaming deltas
  - Role is optional to support streaming chunks where role may not be present

#### Provider-Specific Features
- Full support for **Google Gemini** reasoning controls
  - `reasoning_effort` in provider_specific_params
  - `thinking_budget` parameter
- Full support for **Anthropic Claude** extended thinking
  - Thinking configuration via provider_specific_params
- Full support for **Perplexity** search parameters
  - `search_domain_filter`, `return_citations`, etc.
- Full support for **Alibaba Qwen** thinking controls
- Full support for **xAI Grok** structured responses

#### Code Quality & Best Practices
- **Improved streaming implementation**
  - Better SSE parsing with edge case handling
  - Proper whitespace trimming
  - Graceful handling of empty payloads
- **Smart parameter merging**
  - `extra_body` automatically merged with `provider_specific_params`
  - Maintains compatibility with both OpenAI SDK patterns and Zaguan-native patterns
- **Comprehensive test coverage**
  - Input validation tests
  - Model parameter tests
  - Error handling tests
  - Streaming edge case tests

### Changed
- **Message.role** is now optional to support streaming deltas
  - Non-streaming messages should still provide role
  - Streaming chunks may omit role in delta updates
- **Default timeout** changed from `None` to `30.0` seconds
  - Aligns with SDK specification requirements
  - Prevents indefinite hangs

### Documentation
- Added comprehensive **advanced_features.py** example
  - Demonstrates all provider-specific features
  - Shows error handling patterns
  - Includes context manager usage
- Added **test_validation.py** for security and validation tests
- Added **test_models.py** for model structure tests
- Improved inline documentation and docstrings

### Technical Details

#### SDK Specification Compliance
This release brings the SDK into full compliance with the Zaguan SDK specifications:
- ‚úÖ All required configuration options (SDK_HTTP_CONTRACT.md)
- ‚úÖ All OpenAI-compatible parameters (SDK_CORE_TYPES.md)
- ‚úÖ All Zaguan-specific extensions (SDK_DESIGN_OVERVIEW.md)
- ‚úÖ Proper error handling hierarchy (SDK_PYTHON_IMPLEMENTATION_NOTES.md)
- ‚úÖ Input validation and security (SDK_TESTING_AND_VERSIONING.md)
- ‚úÖ Default timeouts and connection management (SDK_HTTP_CONTRACT.md)

#### Breaking Changes
None. This release is fully backward compatible with existing code.

#### Migration Guide
No migration needed. All changes are additive and backward compatible.

New features can be adopted incrementally:
```python
# Old code still works
request = ChatRequest(
    model="openai/gpt-4o-mini",
    messages=[Message(role="user", content="Hello")]
)

# New features available
request = ChatRequest(
    model="google/gemini-2.5-pro",
    messages=[Message(role="user", content="Hello")],
    reasoning_effort="high",  # New!
    provider_specific_params={  # Enhanced!
        "thinking_budget": 10000
    }
)
```

### Security
- **CVE-None**: No known vulnerabilities
- Input validation prevents injection attacks
- API keys are never logged or exposed
- Proper error handling prevents information leakage

### Performance
- No performance regressions
- Improved streaming efficiency with better buffer handling
- Connection pooling via httpx for better resource utilization

### Testing
- 56 tests passing (100% pass rate)
- New test coverage for:
  - Input validation
  - Error types
  - Model parameters
  - Streaming edge cases
- All tests run in < 0.5 seconds

---

For more information, see the [SDK Documentation](docs/SDK/).

### Added

#### Security & Validation
- **Input validation** for `base_url` and `api_key` in both sync and async clients
  - Prevents empty or whitespace-only values
  - Raises `ValueError` with clear error messages
- **Default timeout** of 30 seconds for all HTTP requests (per SDK specification)
  - Can be overridden via constructor parameter
  - Ensures requests don't hang indefinitely

#### Error Handling
- **BandAccessDeniedError** exception for band-based access control
  - Includes `band`, `required_tier`, and `current_tier` attributes
  - Properly parsed from API error responses
- **Improved streaming error handling**
  - Better handling of malformed SSE data
  - Proper cleanup on HTTP errors
  - Clear error messages for validation failures

#### Model Features (ChatRequest)
- **Audio modalities** support (GPT-4o Audio)
  - `modalities` parameter for specifying output types
  - `audio` parameter for voice and format configuration
- **Reasoning effort** parameter for o1/o3 models
  - Values: "minimal", "low", "medium", "high"
- **DeepSeek thinking control**
  - `thinking` boolean parameter to enable/disable reasoning output
- **Virtual model IDs** support
  - `virtual_model_id` parameter for custom routing
- **Additional OpenAI-compatible parameters**
  - `parallel_tool_calls` for concurrent tool execution
  - `store` for conversation storage
  - `verbosity` for output control
- **extra_body** parameter for OpenAI SDK compatibility
  - Automatically merged with `provider_specific_params`
  - Enables drop-in replacement for OpenAI SDK

#### Message Model Improvements
- **Developer role** support (in addition to system, user, assistant, tool, function)
- **function_call** field for legacy function calling compatibility
- **Flexible role handling** for streaming deltas
  - Role is optional to support streaming chunks where role may not be present

#### Provider-Specific Features
- Full support for **Google Gemini** reasoning controls
  - `reasoning_effort` in provider_specific_params
  - `thinking_budget` parameter
- Full support for **Anthropic Claude** extended thinking
  - Thinking configuration via provider_specific_params
- Full support for **Perplexity** search parameters
  - `search_domain_filter`, `return_citations`, etc.
- Full support for **Alibaba Qwen** thinking controls
- Full support for **xAI Grok** structured responses

#### Code Quality & Best Practices
- **Improved streaming implementation**
  - Better SSE parsing with edge case handling
  - Proper whitespace trimming
  - Graceful handling of empty payloads
- **Smart parameter merging**
  - `extra_body` automatically merged with `provider_specific_params`
  - Maintains compatibility with both OpenAI SDK patterns and Zaguan-native patterns
- **Comprehensive test coverage**
  - Input validation tests
  - Model parameter tests
  - Error handling tests
  - Streaming edge case tests

### Changed
- **Message.role** is now optional to support streaming deltas
  - Non-streaming messages should still provide role
  - Streaming chunks may omit role in delta updates
- **Default timeout** changed from `None` to `30.0` seconds
  - Aligns with SDK specification requirements
  - Prevents indefinite hangs

### Documentation
- Added comprehensive **advanced_features.py** example
  - Demonstrates all provider-specific features
  - Shows error handling patterns
  - Includes context manager usage
- Added **test_validation.py** for security and validation tests
- Added **test_models.py** for model structure tests
- Improved inline documentation and docstrings

### Technical Details

#### SDK Specification Compliance
This release brings the SDK into full compliance with the Zaguan SDK specifications:
- ‚úÖ All required configuration options (SDK_HTTP_CONTRACT.md)
- ‚úÖ All OpenAI-compatible parameters (SDK_CORE_TYPES.md)
- ‚úÖ All Zaguan-specific extensions (SDK_DESIGN_OVERVIEW.md)
- ‚úÖ Proper error handling hierarchy (SDK_PYTHON_IMPLEMENTATION_NOTES.md)
- ‚úÖ Input validation and security (SDK_TESTING_AND_VERSIONING.md)
- ‚úÖ Default timeouts and connection management (SDK_HTTP_CONTRACT.md)

#### Breaking Changes
None. This release is fully backward compatible with existing code.

#### Migration Guide
No migration needed. All changes are additive and backward compatible.

New features can be adopted incrementally:
```python
# Old code still works
request = ChatRequest(
    model="openai/gpt-4o-mini",
    messages=[Message(role="user", content="Hello")]
)

# New features available
request = ChatRequest(
    model="google/gemini-2.5-pro",
    messages=[Message(role="user", content="Hello")],
    reasoning_effort="high",  # New!
    provider_specific_params={  # Enhanced!
        "thinking_budget": 10000
    }
)
```

### Security
- **CVE-None**: No known vulnerabilities
- Input validation prevents injection attacks
- API keys are never logged or exposed
- Proper error handling prevents information leakage

### Performance
- No performance regressions
- Improved streaming efficiency with better buffer handling
- Connection pooling via httpx for better resource utilization

### Testing
- 56 tests passing (100% pass rate)
- New test coverage for:
  - Input validation
  - Error types
  - Model parameters
  - Streaming edge cases
- All tests run in < 0.5 seconds

---

For more information, see the [SDK Documentation](docs/SDK/).
